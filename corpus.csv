Titre,Auteur,Date,URL/ID,Texte,Type
Mass Shooting,Miles_the_new_kid,2024/11/21,https://www.reddit.com//r/comics/comments/1gwdq3y/mass_shooting/,
Sometimes words do hurt a bit,WallOk7138,2024/11/21,https://www.reddit.com//r/MurderedByWords/comments/1gwd3bi/sometimes_words_do_hurt_a_bit/,
Photo of the eruption that started in Iceland a few hours ago,grisigt,2024/11/21,https://www.reddit.com//r/pics/comments/1gwanc5/photo_of_the_eruption_that_started_in_iceland_a/,
this is what this type of parenting leads to,emily-is-happy,2024/11/21,https://www.reddit.com//r/clevercomebacks/comments/1gwca75/this_is_what_this_type_of_parenting_leads_to/,
"Bishnu Shrestha Fought Off 40 Armed Robbers On A Train With A Knife, To Prevent A 18 Year Old Girl From Being Raped ",Kriyaban8,2024/11/21,https://www.reddit.com//r/BeAmazed/comments/1gwd56x/bishnu_shrestha_fought_off_40_armed_robbers_on_a/,"When the intended rape victim's family offered Bishnu Shrestha a large cash reward, he refused it with the following comment: ""Fighting the enemy in battle is my duty as a soldier. Taking on the thugs on the train was my duty as a human being."""
Every time,c0bra_,2024/11/21,https://www.reddit.com//r/memes/comments/1gwaw24/every_time/,
It is the thought that counts.,PreyToTheDemons,2024/11/21,https://www.reddit.com//r/madlads/comments/1gwe0ok/it_is_the_thought_that_counts/,
"In 1977, Bill Gates was arrested for a traffic violation. The outline of his mugshot would go on to be used as a default profile pic for Outlook.",Electrical-Leave818,2024/11/21,https://www.reddit.com//r/interestingasfuck/comments/1gwa2kw/in_1977_bill_gates_was_arrested_for_a_traffic/,
What shall I name my baby based on his scan ,Sad_Cow_577,2024/11/21,https://www.reddit.com//r/notinteresting/comments/1gw93nc/what_shall_i_name_my_baby_based_on_his_scan/,
Ukraine's military says Russia launched intercontinental ballistic missile in the morning,diegolo22,2024/11/21,https://www.reddit.com//r/worldnews/comments/1gwb8ok/ukraines_military_says_russia_launched/,
Many such cases will occur after the tariffs.,collegeqathrowaway,2024/11/21,https://www.reddit.com//r/LeopardsAteMyFace/comments/1gw98o8/many_such_cases_will_occur_after_the_tariffs/,
My fianc√©e made me a life-sized Dark Moon Greatsword for my birthday,jesse9553,2024/11/21,https://www.reddit.com//r/Eldenring/comments/1gwacmo/my_fianc√©e_made_me_a_lifesized_dark_moon/,
"I ordered a salad, they sent me 12 slices of ham",BitOBunny,2024/11/21,https://www.reddit.com//r/mildlyinfuriating/comments/1gw897z/i_ordered_a_salad_they_sent_me_12_slices_of_ham/,"I ordered a salad from Subway using this little robot delivery service my campus has. I get back to my room, and see that my ""salad"" is just a bowl of ham. The cold cut combo is supposed to have three types of meat anyway, why just the ham?? I'm mostly just baffled. I'm upset because it cost nearly $8 and they just gave me ham. "
Greece has decreased almost 50% of its debt to GDP in just 3 years ,No_Firefighter5926,2024/11/21,https://www.reddit.com//r/europe/comments/1gwa6nz/greece_has_decreased_almost_50_of_its_debt_to_gdp/,
üá™üá∫ Eurotrip üá™üá∫,bustytoyxxxo,2024/11/21,https://www.reddit.com//r/mapporncirclejerk/comments/1gwcn1g/eurotrip/,
Shouldn't have tried that,pg_sbucks,2024/11/21,https://www.reddit.com//r/Unexpected/comments/1gw4qj4/shouldnt_have_tried_that/,
Can't understand it whatsoever,hbkdll,2024/11/21,https://www.reddit.com//r/ExplainTheJoke/comments/1gw92d4/cant_understand_it_whatsoever/,
No comment ‚Ä¶,PossessionKindly602,2024/11/21,https://www.reddit.com//r/Funnymemes/comments/1gwbw4k/no_comment/,
The world's shortest and tallest women have tea,ANewTomorrowSoon,2024/11/21,https://www.reddit.com//r/Damnthatsinteresting/comments/1gwaf9v/the_worlds_shortest_and_tallest_women_have_tea/,
I love spongebob ,Immediate_Towel3579,2024/11/21,https://www.reddit.com//r/shitposting/comments/1gw8jh2/i_love_spongebob/,
How these deserts are wrapped up.,IkilledRichieWhelan,2024/11/21,https://www.reddit.com//r/oddlysatisfying/comments/1gw4vja/how_these_deserts_are_wrapped_up/,
This pissed me off to no end,Nervous-Estate-1852,2024/11/21,https://www.reddit.com//r/whenthe/comments/1gw78po/this_pissed_me_off_to_no_end/,
ich_iel,UltraSv3n,2024/11/21,https://www.reddit.com//r/ich_iel/comments/1gwad69/ich_iel/,
"TIL The only known naturally occuring nuclear fission reactor was discovered in Oklo, Gabon and is thought to have been active 1.7 billion years ago.  This discovery in 1972 was made after chemists noticed a significant reduction in fissionable U-235 within the ore coming from the Gabonese mine.",The_Techsan,2024/11/21,https://www.reddit.com//r/todayilearned/comments/1gw4jzl/til_the_only_known_naturally_occuring_nuclear/,
Blursed Reelection ,WhattheDuck9,2024/11/21,https://www.reddit.com//r/blursedimages/comments/1gw89px/blursed_reelection/,
Do men even have feeling ?,YourEmi28,2024/11/21,https://www.reddit.com//r/JustGuysBeingDudes/comments/1gw7nlu/do_men_even_have_feeling/,
"Star Wars Outlaws is dropping 'forced stealth,' so instead of being reset when you get caught sneaking around, you can just start blasting",Temperoar,2024/11/21,https://www.reddit.com//r/gaming/comments/1gw4qq3/star_wars_outlaws_is_dropping_forced_stealth_so/,
Tsunoda almost denied US entry for Las Vegas GP,RJ5466,2024/11/21,https://www.reddit.com//r/formula1/comments/1gw8apd/tsunoda_almost_denied_us_entry_for_las_vegas_gp/,
Meirl,Bubble_Babe_0o0o0o,2024/11/21,https://www.reddit.com//r/meirl/comments/1gw37sv/meirl/,
Intertwined Star Rail Navigation | Trailblazer: Remembrance,HonkaiStarRail,2024/11/21,https://www.reddit.com//r/HonkaiStarRail/comments/1gw7fmc/intertwined_star_rail_navigation_trailblazer/,
"Wow, Who Would've Guessed? ",Monsur_Ausuhnom,2024/11/21,https://www.reddit.com//r/facepalm/comments/1gw4juv/wow_who_wouldve_guessed/,
"Muay Thai fighter, Lerdsila Chumpairtour, displays the top tier reflexes and reaction time that made him a world champion ",Closed_Aperture,2024/11/21,https://www.reddit.com//r/nextfuckinglevel/comments/1gw2eoq/muay_thai_fighter_lerdsila_chumpairtour_displays/,
"It's luck, not talent.",nathan3778,2024/11/21,https://www.reddit.com//r/formuladank/comments/1gwbcm7/its_luck_not_talent/,
Sydney knows when she‚Äôs beat,PmPicturesOfPets,2024/11/21,https://www.reddit.com//r/MadeMeSmile/comments/1gw96lt/sydney_knows_when_shes_beat/,
"Hey Petah, what has the temperature to do here?",KittyKittens1800,2024/11/21,https://www.reddit.com//r/PeterExplainsTheJoke/comments/1gwbcc1/hey_petah_what_has_the_temperature_to_do_here/,
From 2016 and still true,So---buttons,2024/11/21,https://www.reddit.com//r/johnoliver/comments/1gw39sw/from_2016_and_still_true/,
restNamingConvention,fristhon,2024/11/21,https://www.reddit.com//r/ProgrammerHumor/comments/1gw6f4o/restnamingconvention/,
"And it was only the ""Vorgl√ºhen""...",Aggressive-Cod8984,2024/11/21,https://www.reddit.com//r/dankmemes/comments/1gwec83/and_it_was_only_the_vorgl√ºhen/,
Losercity Polygons ,LoganCube100,2024/11/21,https://www.reddit.com//r/Losercity/comments/1gw95he/losercity_polygons/,
Sparkling Eyes,Hazel_Lavenders,2024/11/21,https://www.reddit.com//r/Awww/comments/1gw5bcv/sparkling_eyes/,
Adopted this cute girl that we found on the highway,Crafty_Effort6157,2024/11/21,https://www.reddit.com//r/cats/comments/1gw79e7/adopted_this_cute_girl_that_we_found_on_the/,
"BBC News - ICC issues arrest warrants for Netanyahu, Gallant and Hamas commander",Jackisback123,2024/11/21,https://www.reddit.com//r/news/comments/1gwevag/bbc_news_icc_issues_arrest_warrants_for_netanyahu/,
No one cuts default cubes like weebs.,PlanetAlexProjects,2024/11/21,https://www.reddit.com//r/blender/comments/1gwa268/no_one_cuts_default_cubes_like_weebs/,
"Precious, my precious..",aratanori,2024/11/21,https://www.reddit.com//r/aww/comments/1gw21a3/precious_my_precious/,
Thank you for that information... I guess,TheWebsploiter,2024/11/21,https://www.reddit.com//r/oddlyspecific/comments/1gw4oqx/thank_you_for_that_information_i_guess/,
Roasted until well done and more.,SereeneeRilley,2024/11/21,https://www.reddit.com//r/rareinsults/comments/1gw40pj/roasted_until_well_done_and_more/,
anime_irl,HENADOBEENIN,2024/11/21,https://www.reddit.com//r/anime_irl/comments/1gwdxx1/anime_irl/,
"Laetitia Casta, 1998",Zarathorau,2024/11/21,https://www.reddit.com//r/OldSchoolCool/comments/1gwdrib/laetitia_casta_1998/,
‚ÄúTrans rights are human rights ‚Äî-today and always.‚Äù Illinois Governor Pritzker,Unionpacifbigboy4014,2024/11/21,https://www.reddit.com//r/lgbt/comments/1gw3hwo/trans_rights_are_human_rights_today_and_always/,
Dominating Glenda,l5il,2024/11/21,https://www.reddit.com//r/FunnyAnimals/comments/1gw4mx8/dominating_glenda/,
Swiggy Instamart Ruined Me!,manan-singh,2024/11/21,https://www.reddit.com//r/delhi/comments/1gwd62i/swiggy_instamart_ruined_me/,"Buying condoms isn‚Äôt a big deal, but I usually order them from Blinkit because they send them in a discreet brown package. This time, I decided to try Swiggy Instamart while I was at the office, assuming they‚Äôd use the same kind of packaging. Like an idiot, I told them to drop it off at the office reception desk. To my horror, the package was left there in plain view, right in front of the receptionist. Now, the entire office probably think I do seggs at work! ü´†"
Should credit card interest rates be capped? ,whicky1978,2024/11/21,https://www.reddit.com//r/FluentInFinance/comments/1gw4p8j/should_credit_card_interest_rates_be_capped/,
"In Fifth Element (1997), the case that the stones are put into in 1914 is the same case that Zorg gets later, but it's missing one of the handles. The missing handle is in the gauntlet that is used to regenerate Leeloo.",edwedig,2024/11/21,https://www.reddit.com//r/MovieDetails/comments/1gw34bq/in_fifth_element_1997_the_case_that_the_stones/,
" Right before Jeffrey Dahmer was caught, he had so many bodies piled up in his apartment, that he actually stashed one in the bathtub, where he just stood over it everyday for a month to take a shower",photo_inbloom,2024/11/21,https://www.reddit.com//r/interestingasfuck/comments/1gw7b22/right_before_jeffrey_dahmer_was_caught_he_had_so/,
lost the plot,Hummerous,2024/11/21,https://www.reddit.com//r/CuratedTumblr/comments/1gw7cba/lost_the_plot/,
Mongoose pretends to be dead.,hmle,2024/11/21,https://www.reddit.com//r/AnimalsBeingDerps/comments/1gw286n/mongoose_pretends_to_be_dead/,
My wife became a US citizen today! ,johnhealey17762022,2024/11/21,https://www.reddit.com//r/massachusetts/comments/1gw1i99/my_wife_became_a_us_citizen_today/,They had a nice ceremony at the JFK museum. 
"AOC rejects anti-trans rhetoric from Nancy Mace and Mike Johnson, explaining how their actions will lead to more women being assaulted",TheExitIsThisWay,2024/11/21,https://www.reddit.com//r/PublicFreakout/comments/1gw76r7/aoc_rejects_antitrans_rhetoric_from_nancy_mace/,
"I also attempted a daring goat heist when I was around her age, and sadly, it appears we were both unsuccessful. ",silkie_smooth,2024/11/21,https://www.reddit.com//r/NonPoliticalTwitter/comments/1gw5xdw/i_also_attempted_a_daring_goat_heist_when_i_was/,
He's been training all year for this moment. Throw that foil on and go to work.,JennyBeckman,2024/11/21,https://www.reddit.com//r/BlackPeopleTwitter/comments/1gw2usm/hes_been_training_all_year_for_this_moment_throw/,
Cigarette prices in Australia 2024,post_appt_bliss,2024/11/21,https://www.reddit.com//r/mildlyinteresting/comments/1gw37v2/cigarette_prices_in_australia_2024/,
Musk and Ramaswamy reveal plans to weaponize Supreme Court to push through mass firings and drastic cuts,ObjectiveAd6551,2024/11/21,https://www.reddit.com//r/politics/comments/1gw2tf4/musk_and_ramaswamy_reveal_plans_to_weaponize/,
"No No don‚Äôt repeal Obamacare, repeal the Affordable Care Act. ",h20poIo,2024/11/21,https://www.reddit.com//r/PoliticalHumor/comments/1gw1ubw/no_no_dont_repeal_obamacare_repeal_the_affordable/,
There are no ethics! ,GuiltyBathroom9385,2024/11/21,https://www.reddit.com//r/WhitePeopleTwitter/comments/1gweadw/there_are_no_ethics/,
Who is this for? ,GoodMornEveGoodNight,2024/11/21,https://www.reddit.com//r/CrappyDesign/comments/1gw46uv/who_is_this_for/,
Linda and I finally have a night out lol,Leading_Reply868,2024/11/21,https://www.reddit.com//r/BobsBurgers/comments/1gw2ulw/linda_and_i_finally_have_a_night_out_lol/,
"[No spoilers] Trust me, it's necessary for Act 3",Songkolmae,2024/11/21,https://www.reddit.com//r/arcane/comments/1gwbbp1/no_spoilers_trust_me_its_necessary_for_act_3/,
Maybe maybe maybe,FullmetalPlatypus,2024/11/21,https://www.reddit.com//r/maybemaybemaybe/comments/1gwa370/maybe_maybe_maybe/,
Thought this was a joke until I saw 2 others posted up. ,kandyapples24,2024/11/21,https://www.reddit.com//r/WTF/comments/1gw6l8v/thought_this_was_a_joke_until_i_saw_2_others/,
Suisei checking you out.,Discokidlmao,2024/11/21,https://www.reddit.com//r/Hololive/comments/1gwa8a1/suisei_checking_you_out/,
Federal Inquiry Traced Payments From Gaetz to Women,GoMx808-0,2024/11/21,https://www.reddit.com//r/law/comments/1gw41ng/federal_inquiry_traced_payments_from_gaetz_to/,
2 types of siblings,TCH1610,2024/11/21,https://www.reddit.com//r/LeagueOfMemes/comments/1gwaxqv/2_types_of_siblings/,
"Never understood why this movie received so much backlash. A movie does not have to be perfect in order to be great.I understand Heath set the bar unimaginably high with his Joker performance, but Tom Hardy stole the show and was not at all a disappointment.",funkitxoxox,2024/11/21,https://www.reddit.com//r/moviecritic/comments/1gw8c0k/never_understood_why_this_movie_received_so_much/,
RS26 ICBM re-entry vehicles impacting Dnipro,jimmehi,2024/11/21,https://www.reddit.com//r/UkraineWarVideoReport/comments/1gwckfw/rs26_icbm_reentry_vehicles_impacting_dnipro/,
dancantstream has been banned from Twitch,UltimatumJoker,2024/11/21,https://www.reddit.com//r/LivestreamFail/comments/1gw9hs9/dancantstream_has_been_banned_from_twitch/,
Orange is more traumatized than human who fell down stairs üòÇ,Pixelated047,2024/11/21,https://www.reddit.com//r/OneOrangeBraincell/comments/1gw4d55/orange_is_more_traumatized_than_human_who_fell/,See photo for story. We are now snuggling in his post-bath towel burrito but I‚Äôm afraid he may never recover. The brain cell may be lost forever üòî
Too much air got trapped in the furnace and it exploded,generationxray,2024/11/21,https://www.reddit.com//r/Wellthatsucks/comments/1gw4x6y/too_much_air_got_trapped_in_the_furnace_and_it/,All three of us were home and my mom was on the couch next to where the pressure wave blew through the floor. Thankfully we are all okay and there was no fire. Count your blessings because they are always there somewhere.
"i drew Burnice üëå lmk if you want the n*de version, I‚Äôll send it to you!",Ejol7,2024/11/21,https://www.reddit.com//r/ZenlessZoneZero/comments/1gw7t9o/i_drew_burnice_lmk_if_you_want_the_nde_version/,
"Join IT they said, it'll be fun they said!",TaigaTigerVT,2024/11/21,https://www.reddit.com//r/Grimdank/comments/1gwd3eb/join_it_they_said_itll_be_fun_they_said/,
5700x3d meme,Guest_4710,2024/11/21,https://www.reddit.com//r/pcmasterrace/comments/1gw8t8e/5700x3d_meme/,
Crystal machine making a platter,SweetxDew,2024/11/21,https://www.reddit.com//r/Satisfyingasfuck/comments/1gw1ce6/crystal_machine_making_a_platter/,
"Bought my own place, moving out of bf‚Äôs",Melodic_Tiger5473,2024/11/21,https://www.reddit.com//r/TwoXChromosomes/comments/1gw9uj1/bought_my_own_place_moving_out_of_bfs/,"He tricked me into thinking he was so many things. Then over the last 3 years living together I became the breadwinner, cook, maid, etc.We have been talking about next steps, looking at places together for a year. After our 5th big fight about him not pulling his weight, he threw a tantrum. So the next day I got in the car and drove for hours looking at places I could afford without him. Within a week I found one and made an offer. I stopped cleaning up after him the day it got accepted (well‚Ä¶ mostly anyway)The repairs I needed are wrapping up tomorrow. My new mattress gets to the place Friday. All I have to move are my desk, my clothes and some basic kitchen things- I threw away most of my stuff to come live with him. A bad idea in retrospect, but I thought things would be different.I just looked around at the trash spilling across the kitchen floor, moldy bathroom, the dishes piling up in the sink, and the man snoring in the unclean sheets- wow it feels good to be leaving. The realization I can just build my life without taking on the problems that come with being involved with a man has been such a relief."
Safe world for everyone ,dellaazeem22,2024/11/21,https://www.reddit.com//r/clevercomebacks/comments/1gwd792/safe_world_for_everyone/,
Which one is?,Overreactedpuss,2024/11/21,https://www.reddit.com//r/perfectlycutscreams/comments/1gwblps/which_one_is/,
Gay,HotFireBall,2024/11/21,https://www.reddit.com//r/SipsTea/comments/1gwdu0f/gay/,
It was t gonna organize itself. ,JayGatsby52,2024/11/21,https://www.reddit.com//r/MurderedByWords/comments/1gw7112/it_was_t_gonna_organize_itself/,
A cool guide to How American Households Have Changed Over Time (1960-2023),moktadirr_,2024/11/21,https://www.reddit.com//r/coolguides/comments/1gw4rwq/a_cool_guide_to_how_american_households_have/,
A simple Launch of 5G SIMs was done by BSNL,sixty9e,2024/11/21,https://www.reddit.com//r/IndiaSpeaks/comments/1gw8khd/a_simple_launch_of_5g_sims_was_done_by_bsnl/,
üî•Penguins happily swimming in a pool-like pond. Summer is coming in Antarctica and in some places the ice melts creating ponds. üêß,Sirsilentbob423,2024/11/21,https://www.reddit.com//r/NatureIsFuckingLit/comments/1gwaok7/penguins_happily_swimming_in_a_poollike_pond/,
What industry is struggling way more than people think?,maxxor6868,2024/11/21,https://www.reddit.com//r/AskReddit/comments/1gw4t8y/what_industry_is_struggling_way_more_than_people/,
I make the fires for him. He loves this time of year.,LeftTurnAtAlbuqurque,2024/11/21,https://www.reddit.com//r/Rabbits/comments/1gw5d64/i_make_the_fires_for_him_he_loves_this_time_of/,
"Felt cute, might turn 40 tonight idk",tdurty,2024/11/21,https://www.reddit.com//r/40something/comments/1gw50ds/felt_cute_might_turn_40_tonight_idk/,
Bro either cured his autism or finally found his Barcelona barber.,inferno4039,2024/11/21,https://www.reddit.com//r/soccercirclejerk/comments/1gwaku0/bro_either_cured_his_autism_or_finally_found_his/,
There‚Äôs witnesses and Venmo receipts‚Ä¶..,VladtheInhaler999,2024/11/21,https://www.reddit.com//r/ToiletPaperUSA/comments/1gw8gct/theres_witnesses_and_venmo_receipts/,
Joe Biden Just Trump-Proofed His Hallmark CHIPS Act,Mynameis__--__,2024/11/20,https://www.reddit.com//r/technology/comments/1gvzhtn/joe_biden_just_trumpproofed_his_hallmark_chips_act/,
Mavuika overworld exploration via JOKERVERSE,Ali19371,2024/11/21,https://www.reddit.com//r/Genshin_Impact_Leaks/comments/1gw9vrn/mavuika_overworld_exploration_via_jokerverse/,
Right here baby,ferno2468,2024/11/21,https://www.reddit.com//r/HolUp/comments/1gw272k/right_here_baby/,
aha good try,xurhoneyteen,2024/11/21,https://www.reddit.com//r/suicidebywords/comments/1gwaw5t/aha_good_try/,
I just had to share this‚Ä¶I mean look at this lil‚Äô guy üò≠,CrackheadMerlin,2024/11/21,https://www.reddit.com//r/Eyebleach/comments/1gw1ddo/i_just_had_to_share_thisi_mean_look_at_this_lil/,
[NBAonTNT] Inside The NBA crew does the ‚ÄúSuspect‚Äù challenge,jeric13xd,2024/11/21,https://www.reddit.com//r/nba/comments/1gw25j4/nbaontnt_inside_the_nba_crew_does_the_suspect/,
Hierarchical Dirichlet Process and Relative Entropy,Shui Feng,2022/10/24,http://arxiv.org/abs/2210.13142v1,"The Hierarchical Dirichlet process is a discrete random measure serving as animportant prior in Bayesian non-parametrics. It is motivated with the study ofgroups of clustered data. Each group is modelled through a level two Dirichletprocess and all groups share the same base distribution which itself is a drawnfrom a level one Dirichlet process. It has two concentration parameters withone at each level. The main results of the paper are the law of large numbersand large deviations for the hierarchical Dirichlet process and its mass whenboth concentration parameters converge to infinity. The large deviation ratefunctions are identified explicitly. The rate function for the hierarchicalDirichlet process consists of two terms corresponding to the relative entropiesat each level. It is less than the rate function for the Dirichlet process,which reflects the fact that the number of clusters under the hierarchicalDirichlet process has a slower growth rate than under the Dirichlet process."
Central limit theorems associated with the hierarchical Dirichlet  process,"Shui Feng, J. E. Paguyo",2024/04/24,http://arxiv.org/abs/2404.16034v1,"The Dirichlet process is a discrete random measure specified by aconcentration parameter and a base distribution, and is used as a priordistribution in Bayesian nonparametrics. The hierarchical Dirichlet processgeneralizes the Dirichlet process by randomizing the base distribution througha draw from another Dirichlet process. It is motivated by the study of groupsof clustered data, where the group specific Dirichlet processes are linkedthrough an intergroup Dirichlet process. Focusing on an individual group, thehierarchical Dirichlet process is a discrete random measure whose weights havestronger dependence than the weights of the Dirichlet process. In this paper,we study the asymptotic behavior of the power sum symmetric polynomials for thevector of weights of the hierarchical Dirichlet process when the correspondingconcentration parameters tend to infinity. We establish central limit theoremsand obtain explicit representations for the asymptotic variances, with thelatter clearly showing the impact of the hierarchical structure. These objectsare closely related to the homozygosity in population genetics, the Simpsondiversity index in ecology, and the Herfindahl-Hirschman index in economics."
Spectral analysis of communication networks using Dirichlet eigenvalues,"Alexander Tsiatas, Iraj Saniee, Onuttom Narayan, Matthew Andrews",2011/02/17,http://arxiv.org/abs/1102.3722v2,"The spectral gap of the graph Laplacian with Dirichlet boundary conditions iscomputed for the graphs of several communication networks at the IP-layer,which are subgraphs of the much larger global IP-layer network. We show thatthe Dirichlet spectral gap of these networks is substantially larger than thestandard spectral gap and is likely to remain non-zero in the infinite graphlimit. We first prove this result for finite regular trees, and show that theDirichlet spectral gap in the infinite tree limit converges to the spectral gapof the infinite tree. We also perform Dirichlet spectral clustering on theIP-layer networks and show that it often yields cuts near the network core thatcreate genuine single-component clusters. This is much better than traditionalspectral clustering where several disjoint fragments near the periphery areliable to be misleadingly classified as a single cluster. Spectral clusteringis often used to identify bottlenecks or congestion; since congestion in thesenetworks is known to peak at the core, our results suggest that Dirichletspectral clustering may be better at finding bona-fide bottlenecks."
Dirichlet Process Mixtures of Generalized Mallows Models,"Marina Meila, Harr Chen",2012/03/15,http://arxiv.org/abs/1203.3496v1,"We present a Dirichlet process mixture model over discrete incompleterankings and study two Gibbs sampling inference techniques for estimatingposterior clusterings. The first approach uses a slice sampling subcomponentfor estimating cluster parameters. The second approach marginalizes out severalcluster parameters by taking advantage of approximations to the conditionalposteriors. We empirically demonstrate (1) the effectiveness of thisapproximation for improving convergence, (2) the benefits of the Dirichletprocess model over alternative clustering techniques for ranked data, and (3)the applicability of the approach to exploring large realworld rankingdatasets."
Clustering consistency with Dirichlet process mixtures,"Filippo Ascolani, Antonio Lijoi, Giovanni Rebaudo, Giacomo Zanella",2022/05/25,http://arxiv.org/abs/2205.12924v1,"Dirichlet process mixtures are flexible non-parametric models, particularlysuited to density estimation and probabilistic clustering. In this work westudy the posterior distribution induced by Dirichlet process mixtures as thesample size increases, and more specifically focus on consistency for theunknown number of clusters when the observed data are generated from a finitemixture. Crucially, we consider the situation where a prior is placed on theconcentration parameter of the underlying Dirichlet process. Previous findingsin the literature suggest that Dirichlet process mixtures are typically notconsistent for the number of clusters if the concentration parameter is heldfixed and data come from a finite mixture. Here we show that consistency forthe number of clusters can be achieved if the concentration parameter isadapted in a fully Bayesian way, as commonly done in practice. Our results arederived for data coming from a class of finite mixtures, with mild assumptionson the prior for the concentration parameter and for a variety of choices oflikelihood kernels for the mixture."
A Hierarchical Dirichlet Process Model with Multiple Levels of  Clustering for Human EEG Seizure Modeling,"Drausin Wulsin, Shane Jensen, Brian Litt",2012/06/18,http://arxiv.org/abs/1206.4616v1,"Driven by the multi-level structure of human intracranialelectroencephalogram (iEEG) recordings of epileptic seizures, we introduce anew variant of a hierarchical Dirichlet Process---the multi-level clusteringhierarchical Dirichlet Process (MLC-HDP)---that simultaneously clustersdatasets on multiple levels. Our seizure dataset contains brain activityrecorded in typically more than a hundred individual channels for each seizureof each patient. The MLC-HDP model clusters over channels-types, seizure-types,and patient-types simultaneously. We describe this model and its implementationin detail. We also present the results of a simulation study comparing theMLC-HDP to a similar model, the Nested Dirichlet Process and finallydemonstrate the MLC-HDP's use in modeling seizures across multiple patients. Wefind the MLC-HDP's clustering to be comparable to independent human physicianclusterings. To our knowledge, the MLC-HDP model is the first in the epilepsyliterature capable of clustering seizures within and between patients."
The supervised hierarchical Dirichlet process,"Andrew M. Dai, Amos J. Storkey",2014/12/17,http://arxiv.org/abs/1412.5236v1,"We propose the supervised hierarchical Dirichlet process (sHDP), anonparametric generative model for the joint distribution of a group ofobservations and a response variable directly associated with that whole group.We compare the sHDP with another leading method for regression on grouped data,the supervised latent Dirichlet allocation (sLDA) model. We evaluate our methodon two real-world classification problems and two real-world regressionproblems. Bayesian nonparametric regression models based on the Dirichletprocess, such as the Dirichlet process-generalised linear models (DP-GLM) havepreviously been explored; these models allow flexibility in modelling nonlinearrelationships. However, until now, Hierarchical Dirichlet Process (HDP)mixtures have not seen significant use in supervised problems with grouped datasince a straightforward application of the HDP on the grouped data results inlearnt clusters that are not predictive of the responses. The sHDP solves thisproblem by allowing for clusters to be learnt jointly from the group structureand from the label assigned to each group."
Scalable Inference for Latent Dirichlet Allocation,"James Petterson, Tiberio Caetano",2009/09/25,http://arxiv.org/abs/0909.4603v1,"We investigate the problem of learning a topic model - the well-known LatentDirichlet Allocation - in a distributed manner, using a cluster of C processorsand dividing the corpus to be learned equally among them. We propose a simpleapproximated method that can be tuned, trading speed for accuracy according tothe task at hand. Our approach is asynchronous, and therefore suitable forclusters of heterogenous machines."
Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process  Mixture,"Trevor Campbell, Miao Liu, Brian Kulis, Jonathan P. How, Lawrence Carin",2013/05/28,http://arxiv.org/abs/1305.6659v2,"This paper presents a novel algorithm, based upon the dependent Dirichletprocess mixture model (DDPMM), for clustering batch-sequential data containingan unknown number of evolving clusters. The algorithm is derived via alow-variance asymptotic analysis of the Gibbs sampling algorithm for the DDPMM,and provides a hard clustering with convergence guarantees similar to those ofthe k-means algorithm. Empirical results from a synthetic test with movingGaussian clusters and a test with real ADS-B aircraft trajectory datademonstrate that the algorithm requires orders of magnitude less computationaltime than contemporary probabilistic and hard clustering algorithms, whileproviding higher accuracy on the examined datasets."
Dirichlet-tree multinomial mixtures for clustering microbiome  compositions,"Jialiang Mao, Li Ma",2020/08/02,http://arxiv.org/abs/2008.00400v2,"Studying the human microbiome has gained substantial interest in recentyears, and a common task in the analysis of these data is to cluster microbiomecompositions into subtypes. This subdivision of samples into subgroups servesas an intermediary step in achieving personalized diagnosis and treatment. Inapplying existing clustering methods to modern microbiome studies including theAmerican Gut Project (AGP) data, we found that this seemingly standard task,however, is very challenging in the microbiome composition context due toseveral key features of such data. Standard distance-based clusteringalgorithms generally do not produce reliable results as they do not take intoaccount the heterogeneity of the cross-sample variability among the bacterialtaxa, while existing model-based approaches do not allow sufficient flexibilityfor the identification of complex within-cluster variation from cross-clustervariation. Direct applications of such methods generally lead to overlydispersed clusters in the AGP data and such phenomenon is common for othermicrobiome data. To overcome these challenges, we introduce Dirichlet-treemultinomial mixtures (DTMM) as a Bayesian generative model for clusteringamplicon sequencing data in microbiome studies. DTMM models the microbiomepopulation with a mixture of Dirichlet-tree kernels that utilizes thephylogenetic tree to offer a more flexible covariance structure incharacterizing within-cluster variation, and it provides a means foridentifying a subset of signature taxa that distinguish the clusters. Weperform extensive simulation studies to evaluate the performance of DTMM andcompare it to state-of-the-art model-based and distance-based clusteringmethods in the microbiome context. Finally, we report a case study on the fecaldata from the AGP to identify compositional clusters among individuals withinflammatory bowel disease and diabetes."
Percolation Perturbations in Potential Theory and Random Walks,"Itai Benjamini, Russell Lyons, Oded Schramm",1998/04/02,http://arxiv.org/abs/math/9804010v1,"We show that on a Cayley graph of a nonamenable group, almost surely theinfinite clusters of Bernoulli percolation are transient for simple randomwalk, that simple random walk on these clusters has positive speed, and thatthese clusters admit bounded harmonic functions. A principal new finding onwhich these results are based is that such clusters admit invariant randomsubgraphs with positive isoperimetric constant.  We also show that percolation clusters in any amenable Cayley graph almostsurely admit no nonconstant harmonic Dirichlet functions. Conversely, on aCayley graph admitting nonconstant harmonic Dirichlet functions, almost surelythe infinite clusters of $p$-Bernoulli percolation also have nonconstantharmonic Dirichlet functions when $p$ is sufficiently close to 1. Manyconjectures and questions are presented."
Informed Bayesian Finite Mixture Models via Asymmetric Dirichlet Priors,"Garritt L. Page, Massimo Ventrucci, Maria Franco-Villoria",2023/08/01,http://arxiv.org/abs/2308.00768v1,"Finite mixture models are flexible methods that are commonly used formodel-based clustering. A recent focus in the model-based clustering literatureis to highlight the difference between the number of components in a mixturemodel and the number of clusters. The number of clusters is more relevant froma practical stand point, but to date, the focus of prior distributionformulation has been on the number of components. In light of this, we developa finite mixture methodology that permits eliciting prior information directlyon the number of clusters in an intuitive way. This is done by employing anasymmetric Dirichlet distribution as a prior on the weights of a finitemixture. Further, a penalized complexity motivated prior is employed for theDirichlet shape parameter. We illustrate the ease to which prior informationcan be elicited via our construction and the flexibility of the resultinginduced prior on the number of clusters. We also demonstrate the utility of ourapproach using numerical experiments and two real world data sets."
Numerical conformal mapping with rational functions,Lloyd N. Trefethen,2019/11/09,http://arxiv.org/abs/1911.03696v1,"New algorithms are presented for numerical conformal mapping based onrational approximations and the solution of Dirichlet problems by least-squaresfitting on the boundary. The methods are targeted at regions with corners,where the Dirichlet problem is solved by the ""lightning Laplace solver"" withpoles exponentially clustered near each singularity. For polygons and circularpolygons, further simplifications are possible."
Revisiting k-means: New Algorithms via Bayesian Nonparametrics,"Brian Kulis, Michael I. Jordan",2011/11/02,http://arxiv.org/abs/1111.0352v2,"Bayesian models offer great flexibility for clusteringapplications---Bayesian nonparametrics can be used for modeling infinitemixtures, and hierarchical Bayesian models can be utilized for sharing clustersacross multiple data sets. For the most part, such flexibility is lacking inclassical clustering methods such as k-means. In this paper, we revisit thek-means clustering algorithm from a Bayesian nonparametric viewpoint. Inspiredby the asymptotic connection between k-means and mixtures of Gaussians, we showthat a Gibbs sampling algorithm for the Dirichlet process mixture approaches ahard clustering algorithm in the limit, and further that the resultingalgorithm monotonically minimizes an elegant underlying k-means-like clusteringobjective that includes a penalty for the number of clusters. We generalizethis analysis to the case of clustering multiple data sets through a similarasymptotic argument with the hierarchical Dirichlet process. We also discussfurther extensions that highlight the benefits of our analysis: i) a spectralrelaxation involving thresholded eigenvectors, and ii) a normalized cut graphclustering algorithm that does not fix the number of clusters in the graph."
Bayesian Clustering of Transcription Factor Binding Motifs,"Shane T. Jensen, Jun S. Liu",2006/10/22,http://arxiv.org/abs/math/0610655v1,"Genes are often regulated in living cells by proteins called transcriptionfactors (TFs) that bind directly to short segments of DNA in close proximity tospecific genes. These binding sites have a conserved nucleotide appearance,which is called a motif. Several recent studies of transcriptional regulationrequire the reduction of a large collection of motifs into clusters based onthe similarity of their nucleotide composition. We present a principledapproach to this clustering problem based upon a Bayesian hierarchical modelthat accounts for both within- and between-motif variability. We use aDirichlet process prior distribution that allows the number of clusters to varyand we also present a novel generalization that allows the core width of eachmotif to vary. This clustering model is implemented, using a Gibbs samplingstrategy, on several collections of transcription factor motif matrices. Ourclusters provide a means by which to organize transcription factors based onbinding motif similarities, which can be used to reduce motif redundancy withinlarge databases such as JASPAR and TRANSFAC. Finally, our clustering procedurehas been used in combination with discovery of evolutionarily-conserved motifsto predict co-regulated genes. An alternative to our Dirichlet process priordistribution is explored but shows no substantive difference in the clusteringresults for our datasets. Our Bayesian clustering model based on the Dirichletprocess has several advantages over traditional clustering methods that couldmake our procedure appropriate and useful for many clustering applications."
DIMM-SC: A Dirichlet mixture model for clustering droplet-based single  cell transcriptomic data,"Zhe Sun, Ting Wang, Ke Deng, Xiao-Feng Wang, Robert Lafyatis, Ying Ding, Ming Hu, Wei Chen",2017/04/06,http://arxiv.org/abs/1704.02007v1,"Motivation: Single cell transcriptome sequencing (scRNA-Seq) has become arevolutionary tool to study cellular and molecular processes at single cellresolution. Among existing technologies, the recently developed droplet-basedplatform enables efficient parallel processing of thousands of single cellswith direct counting of transcript copies using Unique Molecular Identifier(UMI). Despite the technology advances, statistical methods and computationaltools are still lacking for analyzing droplet-based scRNA-Seq data.Particularly, model-based approaches for clustering large-scale single celltranscriptomic data are still under-explored. Methods: We developed DIMM-SC, aDirichlet Mixture Model for clustering droplet-based Single Cell transcriptomicdata. This approach explicitly models UMI count data from scRNA-Seq experimentsand characterizes variations across different cell clusters via a Dirichletmixture prior. An expectation-maximization algorithm is used for parameterinference. Results: We performed comprehensive simulations to evaluate DIMM-SCand compared it with existing clustering methods such as K-means, CellTree andSeurat. In addition, we analyzed public scRNA-Seq datasets with known clusterlabels and in-house scRNA-Seq datasets from a study of systemic sclerosis withprior biological knowledge to benchmark and validate DIMM-SC. Both simulationstudies and real data applications demonstrated that overall, DIMM-SC achievessubstantially improved clustering accuracy and much lower clusteringvariability compared to other existing clustering methods. More importantly, asa model-based approach, DIMM-SC is able to quantify the clustering uncertaintyfor each single cell, facilitating rigorous statistical inference andbiological interpretations, which are typically unavailable from existingclustering methods."
Graphical Dirichlet Process for Clustering Non-Exchangeable Grouped Data,"Arhit Chakrabarti, Yang Ni, Ellen Ruth A. Morris, Michael L. Salinas, Robert S. Chapkin, Bani K. Mallick",2023/02/17,http://arxiv.org/abs/2302.09111v2,"We consider the problem of clustering grouped data with possiblynon-exchangeable groups whose dependencies can be characterized by a knowndirected acyclic graph. To allow the sharing of clusters among thenon-exchangeable groups, we propose a Bayesian nonparametric approach, termedgraphical Dirichlet process, that jointly models the dependent group-specificrandom measures by assuming each random measure to be distributed as aDirichlet process whose concentration parameter and base probability measuredepend on those of its parent groups. The resulting joint stochastic processrespects the Markov property of the directed acyclic graph that links thegroups. We characterize the graphical Dirichlet process using a novelhypergraph representation as well as the stick-breaking representation, therestaurant-type representation, and the representation as a limit of a finitemixture model. We develop an efficient posterior inference algorithm andillustrate our model with simulations and a real grouped single-cell dataset."
Consistency Analysis for the Doubly Stochastic Dirichlet Process,"Xing Sun, Nelson H. C. Yung, Edmund Y. Lam, Hayden K. -H. So",2016/05/24,http://arxiv.org/abs/1605.07358v1,"This technical report proves components consistency for the Doubly StochasticDirichlet Process with exponential convergence of posterior probability. Wealso present the fundamental properties for DSDP as well as inferencealgorithms. Simulation toy experiment and real-world experiment results forsingle and multi-cluster also support the consistency proof. This report isalso a support document for the paper ""Computationally Efficient HyperspectralData Learning Based on the Doubly Stochastic Dirichlet Process""."
Unsupervised Outlier Detection using Random Subspace and Subsampling  Ensembles of Dirichlet Process Mixtures,"Dongwook Kim, Juyeon Park, Hee Cheol Chung, Seonghyun Jeong",2024/01/01,http://arxiv.org/abs/2401.00773v3,"Probabilistic mixture models are recognized as effective tools forunsupervised outlier detection owing to their interpretability and globalcharacteristics. Among these, Dirichlet process mixture models stand out as astrong alternative to conventional finite mixture models for both clusteringand outlier detection tasks. Unlike finite mixture models, Dirichlet processmixtures are infinite mixture models that automatically determine the number ofmixture components based on the data. Despite their advantages, the adoption ofDirichlet process mixture models for unsupervised outlier detection has beenlimited by challenges related to computational inefficiency and sensitivity tooutliers in the construction of outlier detectors. Additionally, Dirichletprocess Gaussian mixtures struggle to effectively model non-Gaussian data withdiscrete or binary features. To address these challenges, we propose a noveloutlier detection method that utilizes ensembles of Dirichlet process Gaussianmixtures. This unsupervised algorithm employs random subspace and subsamplingensembles to ensure efficient computation and improve the robustness of theoutlier detector. The ensemble approach further improves the suitability of theproposed method for detecting outliers in non-Gaussian data. Furthermore, ourmethod uses variational inference for Dirichlet process mixtures, which ensuresboth efficient and rapid computation. Empirical analyses using benchmarkdatasets demonstrate that our method outperforms existing approaches inunsupervised outlier detection."
"Powered Dirichlet Process for Controlling the Importance of  ""Rich-Get-Richer"" Prior Assumptions in Bayesian Clustering","Ga√´l Poux-M√©dard, Julien Velcin, Sabine Loudcher",2021/04/26,http://arxiv.org/abs/2104.12485v1,"One of the most used priors in Bayesian clustering is the Dirichlet prior. Itcan be expressed as a Chinese Restaurant Process. This process allowsnonparametric estimation of the number of clusters when partitioning datasets.Its key feature is the ""rich-get-richer"" property, which assumes a cluster hasan a priori probability to get chosen linearly dependent on population. In thispaper, we show that such prior is not always the best choice to model data. Wederive the Powered Chinese Restaurant process from a modified version of theDirichlet-Multinomial distribution to answer this problem. We then develop someof its fundamental properties (expected number of clusters, convergence).Unlike state-of-the-art efforts in this direction, this new formulation allowsfor direct control of the importance of the ""rich-get-richer"" prior."
Flexible clustering via hidden hierarchical Dirichlet priors,"Antonio Lijoi, Igor Pr√ºnster, Giovanni Rebaudo",2022/01/18,http://arxiv.org/abs/2201.06994v1,"The Bayesian approach to inference stands out for naturally allowingborrowing information across heterogeneous populations, with different samplespossibly sharing the same distribution. A popular Bayesian nonparametric modelfor clustering probability distributions is the nested Dirichlet process, whichhowever has the drawback of grouping distributions in a single cluster whenties are observed across samples. With the goal of achieving a flexible andeffective clustering method for both samples and observations, we investigate anonparametric prior that arises as the composition of two different discreterandom structures and derive a closed-form expression for the induceddistribution of the random partition, the fundamental tool regulating theclustering behavior of the model. On the one hand, this allows to gain a deeperinsight into the theoretical properties of the model and, on the other hand, ityields an MCMC algorithm for evaluating Bayesian inferences of interest.Moreover, we single out limitations of this algorithm when working with morethan two populations and, consequently, devise an alternative more efficientsampling scheme, which as a by-product, allows testing homogeneity betweendifferent populations. Finally, we perform a comparison with the nestedDirichlet process and provide illustrative examples of both synthetic and realdata."
A Bayesian View of the Poisson-Dirichlet Process,"Wray Buntine, Marcus Hutter",2010/07/02,http://arxiv.org/abs/1007.0296v2,"The two parameter Poisson-Dirichlet Process (PDP), a generalisation of theDirichlet Process, is increasingly being used for probabilistic modelling indiscrete areas such as language technology, bioinformatics, and image analysis.There is a rich literature about the PDP and its derivative distributions suchas the Chinese Restaurant Process (CRP). This article reviews some of the basictheory and then the major results needed for Bayesian modelling of discreteproblems including details of priors, posteriors and computation.  The PDP allows one to build distributions over countable partitions. The PDPhas two other remarkable properties: first it is partially conjugate to itself,which allows one to build hierarchies of PDPs, and second using a marginalisedrelative the CRP, one gets fragmentation and clustering properties that letsone layer partitions to build trees. This article presents the basic theory forunderstanding the notion of partitions and distributions over them, the PDP andthe CRP, and the important properties of conjugacy, fragmentation andclustering, as well as some key related properties such as consistency andconvergence. This article also presents a Bayesian interpretation of thePoisson-Dirichlet process based on an improper and infinite dimensionalDirichlet distribution. This means we can understand the process as justanother Dirichlet and thus all its sampling properties emerge naturally.  The theory of PDPs is usually presented for continuous distributions (moregenerally referred to as non-atomic distributions), however, when applied todiscrete distributions its remarkable conjugacy property emerges. This contextand basic results are also presented, as well as techniques for computing thesecond order Stirling numbers that occur in the posteriors for discretedistributions."
From here to infinity - sparse finite versus Dirichlet process mixtures  in model-based clustering,"Sylvia Fr√ºhwirth-Schnatter, Gertraud Malsiner-Walli",2017/06/22,http://arxiv.org/abs/1706.07194v3,"In model-based-clustering mixture models are used to group data points intoclusters. A useful concept introduced for Gaussian mixtures by Malsiner Walliet al (2016) are sparse finite mixtures, where the prior distribution on theweight distribution of a mixture with $K$ components is chosen in such a waythat a priori the number of clusters in the data is random and is allowed to besmaller than $K$ with high probability. The number of cluster is then inferreda posteriori from the data.  The present paper makes the following contributions in the context of sparsefinite mixture modelling. First, it is illustrated that the concept of sparsefinite mixture is very generic and easily extended to cluster various types ofnon-Gaussian data, in particular discrete data and continuous multivariate dataarising from non-Gaussian clusters. Second, sparse finite mixtures are comparedto Dirichlet process mixtures with respect to their ability to identify thenumber of clusters. For both model classes, a random hyper prior is consideredfor the parameters determining the weight distribution. By suitable matching ofthese priors, it is shown that the choice of this hyper prior is far moreinfluential on the cluster solution than whether a sparse finite mixture or aDirichlet process mixture is taken into consideration."
Flexible Priors for Exemplar-based Clustering,"Daniel Tarlow, Richard S. Zemel, Brendan J. Frey",2012/06/13,http://arxiv.org/abs/1206.3294v1,"Exemplar-based clustering methods have been shown to produce state-of-the-artresults on a number of synthetic and real-world clustering problems. They areappealing because they offer computational benefits over latent-mean models andcan handle arbitrary pairwise similarity measures between data points. However,when trying to recover underlying structure in clustering problems, tailoredsimilarity measures are often not enough; we also desire control over thedistribution of cluster sizes. Priors such as Dirichlet process priors allowthe number of clusters to be unspecified while expressing priors over datapartitions. To our knowledge, they have not been applied to exemplar-basedmodels. We show how to incorporate priors, including Dirichlet process priors,into the recently introduced affinity propagation algorithm. We develop anefficient maxproduct belief propagation algorithm for our new model anddemonstrate experimentally how the expanded range of clustering priors allowsus to better recover true clusterings in situations where we have someinformation about the generating process."
Parallel Clustering of Single Cell Transcriptomic Data with Split-Merge  Sampling on Dirichlet Process Mixtures,"Tiehang Duan, Jos√© P. Pinto, Xiaohui Xie",2018/12/25,http://arxiv.org/abs/1812.10048v1,"Motivation: With the development of droplet based systems, massive singlecell transcriptome data has become available, which enables analysis ofcellular and molecular processes at single cell resolution and is instrumentalto understanding many biological processes. While state-of-the-art clusteringmethods have been applied to the data, they face challenges in the followingaspects: (1) the clustering quality still needs to be improved; (2) most modelsneed prior knowledge on number of clusters, which is not always available; (3)there is a demand for faster computational speed. Results: We propose to tacklethese challenges with Parallel Split Merge Sampling on Dirichlet ProcessMixture Model (the Para-DPMM model). Unlike classic DPMM methods that performsampling on each single data point, the split merge mechanism samples on thecluster level, which significantly improves convergence and optimality of theresult. The model is highly parallelized and can utilize the computing power ofhigh performance computing (HPC) clusters, enabling massive clustering on hugedatasets. Experiment results show the model outperforms current widely usedmodels in both clustering quality and computational speed. Availability: Sourcecode is publicly available onhttps://github.com/tiehangd/Para_DPMM/tree/master/Para_DPMM_package"
Tensor Dirichlet Process Multinomial Mixture Model for Passenger  Trajectory Clustering,"Ziyue Li, Hao Yan, Chen Zhang, Andi Wang, Wolfgang Ketter, Lijun Sun, Fugee Tsung",2023/06/23,http://arxiv.org/abs/2306.13794v1,"Passenger clustering based on travel records is essential for transportationoperators. However, existing methods cannot easily cluster the passengers dueto the hierarchical structure of the passenger trip information, namely: eachpassenger has multiple trips, and each trip contains multi-dimensionalmulti-mode information. Furthermore, existing approaches rely on an accuratespecification of the clustering number to start, which is difficult whenmillions of commuters are using the transport systems on a daily basis. In thispaper, we propose a novel Tensor Dirichlet Process Multinomial Mixture model(Tensor-DPMM), which is designed to preserve the multi-mode and hierarchicalstructure of the multi-dimensional trip information via tensor, and clusterthem in a unified one-step manner. The model also has the ability to determinethe number of clusters automatically by using the Dirichlet Process to decidethe probabilities for a passenger to be either assigned in an existing clusteror to create a new cluster: This allows our model to grow the clusters asneeded in a dynamic manner. Finally, existing methods do not consider spatialsemantic graphs such as geographical proximity and functional similaritybetween the locations, which may cause inaccurate clustering. To this end, wefurther propose a variant of our model, namely the Tensor-DPMM with Graph. Forthe algorithm, we propose a tensor Collapsed Gibbs Sampling method, with aninnovative step of ""disband and relocating"", which disbands clusters with toosmall amount of members and relocates them to the remaining clustering. Thisavoids uncontrollable growing amounts of clusters. A case study based on HongKong metro passenger data is conducted to demonstrate the automatic process oflearning the number of clusters, and the learned clusters are better inwithin-cluster compactness and cross-cluster separateness."
Hierarchical Latent Word Clustering,"Halid Ziya Yerebakan, Fitsum Reda, Yiqiang Zhan, Yoshihisa Shinagawa",2016/01/20,http://arxiv.org/abs/1601.05472v1,"This paper presents a new Bayesian non-parametric model by extending theusage of Hierarchical Dirichlet Allocation to extract tree structured wordclusters from text data. The inference algorithm of the model collects words ina cluster if they share similar distribution over documents. In ourexperiments, we observed meaningful hierarchical structures on NIPS corpus andradiology reports collected from public repositories."
An efficient algorithm for solving elliptic problems on percolation  clusters,Chenlin Gu,2019/07/31,http://arxiv.org/abs/1907.13571v1,"We present an efficient algorithm to solve elliptic Dirichlet problemsdefined on the cluster of $\mathbb{Z}^d$ supercritical Bernoulli percolation,as a generalization of the iterative method proposed by S. Armstrong, A.Hannukainen, T. Kuusi and J.-C. Mourrat. We also explore the two-scaleexpansion on the infinite cluster of percolation, and use it to give a rigorousanalysis of the algorithm."
Colouring and breaking sticks: random distributions and heterogeneous  clustering,Peter J. Green,2010/03/21,http://arxiv.org/abs/1003.3988v1,"We begin by reviewing some probabilistic results about the Dirichlet Processand its close relatives, focussing on their implications for statisticalmodelling and analysis. We then introduce a class of simple mixture models inwhich clusters are of different `colours', with statistical characteristicsthat are constant within colours, but different between colours. Thus clusteridentities are exchangeable only within colours. The basic form of our model isa variant on the familiar Dirichlet process, and we find that much of thestandard modelling and computational machinery associated with the Dirichletprocess may be readily adapted to our generalisation. The methodology isillustrated with an application to the partially-parametric clustering of geneexpression profiles."
Beta-Product Poisson-Dirichlet Processes,"Federico Bassetti, Roberto Casarin, Fabrizio Leisen",2011/09/22,http://arxiv.org/abs/1109.4777v1,"Time series data may exhibit clustering over time and, in a multiple timeseries context, the clustering behavior may differ across the series. Thispaper is motivated by the Bayesian non--parametric modeling of the dependencebetween the clustering structures and the distributions of different timeseries. We follow a Dirichlet process mixture approach and introduce a newclass of multivariate dependent Dirichlet processes (DDP). The proposed DDP arerepresented in terms of vector of stick-breaking processes with dependentweights. The weights are beta random vectors that determine different anddependent clustering effects along the dimension of the DDP vector. We discusssome theoretical properties and provide an efficient Monte Carlo Markov Chainalgorithm for posterior computation. The effectiveness of the method isillustrated with a simulation study and an application to the United States andthe European Union industrial production indexes."
Conjoined Dirichlet Process,"Michelle N. Ngo, Dustin S. Pluta, Alexander N. Ngo, Babak Shahbaba",2020/02/08,http://arxiv.org/abs/2002.03223v1,"Biclustering is a class of techniques that simultaneously clusters the rowsand columns of a matrix to sort heterogeneous data into homogeneous blocks.Although many algorithms have been proposed to find biclusters, existingmethods suffer from the pre-specification of the number of biclusters or placeconstraints on the model structure. To address these issues, we develop anovel, non-parametric probabilistic biclustering method based on Dirichletprocesses to identify biclusters with strong co-occurrence in both rows andcolumns. The proposed method utilizes dual Dirichlet process mixture models tolearn row and column clusters, with the number of resulting clusters determinedby the data rather than pre-specified. Probabilistic biclusters are identifiedby modeling the mutual dependence between the row and column clusters. We applyour method to two different applications, text mining and gene expressionanalysis, and demonstrate that our method improves bicluster extraction in manysettings compared to existing approaches."
On the Variational Posterior of Dirichlet Process Deep Latent Gaussian  Mixture Models,"Amine Echraibi, Joachim Flocon-Cholet, St√©phane Gosselin, Sandrine Vaton",2020/06/16,http://arxiv.org/abs/2006.08993v2,"Thanks to the reparameterization trick, deep latent Gaussian models haveshown tremendous success recently in learning latent representations. Theability to couple them however with nonparamet-ric priors such as the DirichletProcess (DP) hasn't seen similar success due to its non parameteriz-ablenature. In this paper, we present an alternative treatment of the variationalposterior of the Dirichlet Process Deep Latent Gaussian Mixture Model(DP-DLGMM), where we show that the prior cluster parameters and the variationalposteriors of the beta distributions and cluster hidden variables can beupdated in closed-form. This leads to a standard reparameterization trick onthe Gaussian latent variables knowing the cluster assignments. We demonstrateour approach on standard benchmark datasets, we show that our model is capableof generating realistic samples for each cluster obtained, and manifestscompetitive performance in a semi-supervised setting."
Powered Hawkes-Dirichlet Process: Challenging Textual Clustering using a  Flexible Temporal Prior,"Ga√´l Poux-M√©dard, Julien Velcin, Sabine Loudcher",2021/09/15,http://arxiv.org/abs/2109.07170v1,"The textual content of a document and its publication date are intertwined.For example, the publication of a news article on a topic is influenced byprevious publications on similar issues, according to underlying temporaldynamics. However, it can be challenging to retrieve meaningful informationwhen textual information conveys little information or when temporal dynamicsare hard to unveil. Furthermore, the textual content of a document is notalways linked to its temporal dynamics. We develop a flexible method to createclusters of textual documents according to both their content and publicationtime, the Powered Dirichlet-Hawkes process (PDHP). We show PDHP yieldssignificantly better results than state-of-the-art models when temporalinformation or textual content is weakly informative. The PDHP also alleviatesthe hypothesis that textual content and temporal dynamics are always perfectlycorrelated. PDHP allows retrieving textual clusters, temporal clusters, or amixture of both with high accuracy when they are not. We demonstrate that PDHPgeneralizes previous work --such as the Dirichlet-Hawkes process (DHP) andUniform process (UP). Finally, we illustrate the changes induced by PDHP overDHP and UP in a real-world application using Reddit data."
Similarity-based Random Partition Distribution for Clustering Functional  Data,"Tomoya Wakayama, Shonosuke Sugasawa, Genya Kobayashi",2023/08/03,http://arxiv.org/abs/2308.01704v3,"Random partition distribution is a crucial tool for model-based clustering.This study advances the field of random partition in the context of functionalspatial data, focusing on the challenges posed by hourly population data acrossvarious regions and dates. We propose an extended generalized Dirichletprocess, named the similarity-based generalized Dirichlet process (SGDP), toaddress the limitations of simple random partition distributions (e.g., thoseinduced by the Dirichlet process), such as an overabundance of clusters. Thismodel prevents excess cluster production as well as incorporates pairwisesimilarity information to ensure accurate and meaningful grouping. Thetheoretical properties of the SGDP are studied. Then, SGDP-based randompartition is applied to a real-world dataset of hourly population flow in$500\text{m}^2$ meshes in the central part of Tokyo. In this empirical context,our method excels at detecting meaningful patterns in the data while accountingfor spatial nuances. The results underscore the adaptability and utility of themethod, showcasing its prowess in revealing intricate spatiotemporal dynamics.The proposed SGDP will significantly contribute to urban planning,transportation, and policy-making and will be a helpful tool for understandingpopulation dynamics and their implications."
"Nonparametric Variable Selection, Clustering and Prediction for  High-Dimensional Regression","Subharup Guha, Veerabhadran Baladandayuthapani",2014/07/21,http://arxiv.org/abs/1407.5472v3,"The development of parsimonious models for reliable inference and predictionof responses in high-dimensional regression settings is often challenging dueto relatively small sample sizes and the presence of complex interactionpatterns between a large number of covariates. We propose an efficient,nonparametric framework for simultaneous variable selection, clustering andprediction in high-throughput regression settings with continuous or discreteoutcomes, called VariScan. The VariScan model utilizes the sparsity induced byPoisson-Dirichlet processes (PDPs) to group the covariates intolower-dimensional latent clusters consisting of covariates with similarpatterns among the samples. The data are permitted to direct the choice of asuitable cluster allocation scheme, choosing between PDPs and their specialcase, a Dirichlet process. Subsequently, the latent clusters are used to builda nonlinear prediction model for the responses using an adaptive mixture oflinear and nonlinear elements, thus achieving a balance between model parsimonyand flexibility. We investigate theoretical properties of the VariScanprocedure that differentiate the allocations patterns of PDPs and Dirichletprocesses both in terms of the number and relative sizes of their clusters.Additional theoretical results guarantee the high accuracy of the model-basedclustering procedure, and establish model selection and prediction consistency.Through simulation studies and analyses of benchmark data sets, we demonstratethe reliability of VariScan's clustering mechanism and show that the techniquecompares favorably to, and often outperforms, existing methodologies in termsof the prediction accuracies of the subject-specific responses."
Fair Clustering via Hierarchical Fair-Dirichlet Process,"Abhisek Chakraborty, Anirban Bhattacharya, Debdeep Pati",2023/05/27,http://arxiv.org/abs/2305.17557v1,"The advent of ML-driven decision-making and policy formation has led to anincreasing focus on algorithmic fairness. As clustering is one of the mostcommonly used unsupervised machine learning approaches, there has naturallybeen a proliferation of literature on {\em fair clustering}. A popular notionof fairness in clustering mandates the clusters to be {\em balanced}, i.e.,each level of a protected attribute must be approximately equally representedin each cluster. Building upon the original framework, this literature hasrapidly expanded in various aspects. In this article, we offer a novelmodel-based formulation of fair clustering, complementing the existingliterature which is almost exclusively based on optimizing appropriateobjective functions."
DIVA: A Dirichlet Process Mixtures Based Incremental Deep Clustering  Algorithm via Variational Auto-Encoder,"Zhenshan Bing, Yuan Meng, Yuqi Yun, Hang Su, Xiaojie Su, Kai Huang, Alois Knoll",2023/05/23,http://arxiv.org/abs/2305.14067v3,"Generative model-based deep clustering frameworks excel in classifyingcomplex data, but are limited in handling dynamic and complex features becausethey require prior knowledge of the number of clusters. In this paper, wepropose a nonparametric deep clustering framework that employs an infinitemixture of Gaussians as a prior. Our framework utilizes a memoized onlinevariational inference method that enables the ""birth"" and ""merge"" moves ofclusters, allowing our framework to cluster data in a ""dynamic-adaptive""manner, without requiring prior knowledge of the number of features. We namethe framework as DIVA, a Dirichlet Process-based Incremental deep clusteringframework via Variational Auto-Encoder. Our framework, which outperformsstate-of-the-art baselines, exhibits superior performance in classifyingcomplex data with dynamically changing features, particularly in the case ofincremental features. We released our source code implementation at:https://github.com/Ghiara/diva"
Product Centered Dirichlet Processes for Bayesian Multiview Clustering,"Alexander Dombowsky, David B. Dunson",2023/12/08,http://arxiv.org/abs/2312.05365v3,"While there is an immense literature on Bayesian methods for clustering, themultiview case has received little attention. This problem focuses on obtainingdistinct but statistically dependent clusterings in a common set of entitiesfor different data types. For example, clustering patients into subgroups withsubgroup membership varying according to the domain of the patient variables. Achallenge is how to model the across-view dependence between the partitions ofpatients into subgroups. The complexities of the partition space make standardmethods to model dependence, such as correlation, infeasible. In this article,we propose CLustering with Independence Centering (CLIC), a clustering priorthat uses a single parameter to explicitly model dependence between clusteringsacross views. CLIC is induced by the product centered Dirichlet process (PCDP),a novel hierarchical prior that bridges between independent and equivalentpartitions. We show appealing theoretic properties, provide a finiteapproximation and prove its accuracy, present a marginal Gibbs sampler forposterior computation, and derive closed form expressions for the marginal andjoint partition distributions for the CLIC model. On synthetic data and in anapplication to epidemiology, CLIC accurately characterizes view-specificpartitions while providing inference on the dependence level."
Invariant Percolation and Harmonic Dirichlet Functions,Damien Gaboriau,2004/05/24,http://arxiv.org/abs/math/0405458v3,"The main goal of this paper is to answer question 1.10 and settle conjecture1.11 of Benjamini-Lyons-Schramm [BLS99] relating harmonic Dirichlet functionson a graph to those of the infinite clusters in the uniqueness phase ofBernoulli percolation. We extend the result to more general invariantpercolations, including the Random-Cluster model. We prove the existence of thenonuniqueness phase for the Bernoulli percolation (and make some progress forRandom-Cluster model) on unimodular transitive locally finite graphs admittingnonconstant harmonic Dirichlet functions. This is done by using the device of$\ell^2$ Betti numbers."
Bayesian Nonparametric Multilevel Clustering with Group-Level Contexts,"Vu Nguyen, Dinh Phung, XuanLong Nguyen, Svetha Venkatesh, Hung Hai Bui",2014/01/09,http://arxiv.org/abs/1401.1974v4,"We present a Bayesian nonparametric framework for multilevel clustering whichutilizes group-level context information to simultaneously discoverlow-dimensional structures of the group contents and partitions groups intoclusters. Using the Dirichlet process as the building block, our modelconstructs a product base-measure with a nested structure to accommodatecontent and context observations at multiple levels. The proposed modelpossesses properties that link the nested Dirichlet processes (nDP) and theDirichlet process mixture models (DPM) in an interesting way: integrating outall contents results in the DPM over contexts, whereas integrating outgroup-specific contexts results in the nDP mixture over content variables. Weprovide a Polya-urn view of the model and an efficient collapsed Gibbsinference procedure. Extensive experiments on real-world datasets demonstratethe advantage of utilizing context information via our model in both text andimage domains."
Bayesian mixture models (in)consistency for the number of clusters,"Louise Alamichel, Daria Bystrova, Julyan Arbel, Guillaume Kon Kam King",2022/10/25,http://arxiv.org/abs/2210.14201v3,"Bayesian nonparametric mixture models are common for modeling complex data.While these models are well-suited for density estimation, recent resultsproved posterior inconsistency of the number of clusters when the true numberof components is finite, for the Dirichlet process and Pitman--Yor processmixture models. We extend these results to additional Bayesian nonparametricpriors such as Gibbs-type processes and finite-dimensional representationsthereof. The latter include the Dirichlet multinomial process, the recentlyproposed Pitman-Yor, and normalized generalized gamma multinomial processes. Weshow that mixture models based on these processes are also inconsistent in thenumber of clusters and discuss possible solutions. Notably, we show that apost-processing algorithm introduced for the Dirichlet process can be extendedto more general models and provides a consistent method to estimate the numberof components."
Covariate-dependent hierarchical Dirichlet process,"Huizi Zhang, Sara Wade, Natalia Bochkina",2024/07/02,http://arxiv.org/abs/2407.02676v2,"The intricacies inherent in contemporary real datasets demand more advancedstatistical models to effectively address complex challenges. In this articlewe delve into problems related to identifying clusters across related groups,when additional covariate information is available. We formulate a novelBayesian nonparametric approach based on mixture models, integrating ideas fromthe hierarchical Dirichlet process and ""single-atoms"" dependent Dirichletprocess. The proposed method exhibits exceptional generality and flexibility,accommodating both continuous and discrete covariates through the utilizationof appropriate kernel functions. We construct a robust and efficient Markovchain Monte Carlo (MCMC) algorithm involving data augmentation to tackle theintractable normalized weights. The versatility of the proposed model extendsour capability to discern the relationship between covariates and clusters.Through testing on both simulated and real-world datasets, our modeldemonstrates its capacity to identify meaningful clusters across groups,providing valuable insights for a spectrum of applications."
Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with  Graphs for Passenger Trajectory Clustering,"Ziyue Li, Hao Yan, Chen Zhang, Lijun Sun, Wolfgang Ketter, Fugee Tsung",2023/10/31,http://arxiv.org/abs/2310.20224v1,"Passenger clustering based on trajectory records is essential fortransportation operators. However, existing methods cannot easily cluster thepassengers due to the hierarchical structure of the passenger trip information,including multiple trips within each passenger and multi-dimensionalinformation about each trip. Furthermore, existing approaches rely on anaccurate specification of the clustering number to start. Finally, existingmethods do not consider spatial semantic graphs such as geographical proximityand functional similarity between the locations. In this paper, we propose anovel tensor Dirichlet Process Multinomial Mixture model with graphs, which canpreserve the hierarchical structure of the multi-dimensional trip informationand cluster them in a unified one-step manner with the ability to determine thenumber of clusters automatically. The spatial graphs are utilized in communitydetection to link the semantic neighbors. We further propose a tensor versionof Collapsed Gibbs Sampling method with a minimum cluster size requirement. Acase study based on Hong Kong metro passenger data is conducted to demonstratethe automatic process of cluster amount evolution and better cluster qualitymeasured by within-cluster compactness and cross-cluster separateness. The codeis available at https://github.com/bonaldli/TensorDPMM-G."
Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick  Breaking Representation,"Ian Porteous, Alexander T. Ihler, Padhraic Smyth, Max Welling",2012/06/27,http://arxiv.org/abs/1206.6845v1,"Nonparametric Bayesian approaches to clustering, information retrieval,language modeling and object recognition have recently shown great promise as anew paradigm for unsupervised data analysis. Most contributions have focused onthe Dirichlet process mixture models or extensions thereof for which efficientGibbs samplers exist. In this paper we explore Gibbs samplers for infinitecomplexity mixture models in the stick breaking representation. The advantageof this representation is improved modeling flexibility. For instance, one candesign the prior distribution over cluster sizes or couple multiple infinitemixture models (e.g. over time) at the level of their parameters (i.e. thedependent Dirichlet process model). However, Gibbs samplers for infinitemixture models (as recently introduced in the statistics literature) seem tomix poorly over cluster labels. Among others issues, this can have the adverseeffect that labels for the same cluster in coupled mixture models are mixed up.We introduce additional moves in these samplers to improve mixing over clusterlabels and to bring clusters into correspondence. An application to modeling ofstorm trajectories is used to illustrate these ideas."
Functional clustering in nested designs: Modeling variability in  reproductive epidemiology studies,"Abel Rodriguez, David B. Dunson",2014/11/20,http://arxiv.org/abs/1411.5510v1,"We discuss functional clustering procedures for nested designs, wheremultiple curves are collected for each subject in the study. We start byconsidering the application of standard functional clustering tools to thisproblem, which leads to groupings based on the average profile for eachsubject. After discussing some of the shortcomings of this approach, we presenta mixture model based on a generalization of the nested Dirichlet process thatclusters subjects based on the distribution of their curves. By using mixturesof generalized Dirichlet processes, the model induces a much more flexibleprior on the partition structure than other popular model-based clusteringmethods, allowing for different rates of introduction of new clusters as thenumber of observations increases. The methods are illustrated using hormoneprofiles from multiple menstrual cycles collected for women in the EarlyPregnancy Study."
Posterior Distribution for the Number of Clusters in Dirichlet Process  Mixture Models,"Chiao-Yu Yang, Eric Xia, Nhat Ho, Michael I. Jordan",2019/05/23,http://arxiv.org/abs/1905.09959v2,"Dirichlet process mixture models (DPMM) play a central role in Bayesiannonparametrics, with applications throughout statistics and machine learning.DPMMs are generally used in clustering problems where the number of clusters isnot known in advance, and the posterior distribution is treated as providinginference for this number. Recently, however, it has been shown that the DPMMis inconsistent in inferring the true number of components in certain cases.This is an asymptotic result, and it would be desirable to understand whetherit holds with finite samples, and to more fully understand the full posterior.In this work, we provide a rigorous study for the posterior distribution of thenumber of clusters in DPMM under different prior distributions on theparameters and constraints on the distributions of the data. We provide novellower bounds on the ratios of probabilities between $s+1$ clusters and $s$clusters when the prior distributions on parameters are chosen to be Gaussianor uniform distributions."
Topic Detection from Conversational Dialogue Corpus with Parallel  Dirichlet Allocation Model and Elbow Method,"Haider Khalid, Vincent Wade",2020/06/05,http://arxiv.org/abs/2006.03353v1,"A conversational system needs to know how to switch between topics tocontinue the conversation for a more extended period. For this topic detectionfrom dialogue corpus has become an important task for a conversation andaccurate prediction of conversation topics is important for creating coherentand engaging dialogue systems. In this paper, we proposed a topic detectionapproach with Parallel Latent Dirichlet Allocation (PLDA) Model by clustering avocabulary of known similar words based on TF-IDF scores and Bag of Words (BOW)technique. In the experiment, we use K-mean clustering with Elbow Method forinterpretation and validation of consistency within-cluster analysis to selectthe optimal number of clusters. We evaluate our approach by comparing it withtraditional LDA and clustering technique. The experimental results show thatcombining PLDA with Elbow method selects the optimal number of clusters andrefine the topics for the conversation."
Bayesian nonparametric temporal dynamic clustering via autoregressive  Dirichlet priors,"Maria De Iorio, Stefano Favaro, Alessandra Guglielmi, Lifeng Ye",2019/10/23,http://arxiv.org/abs/1910.10443v1,"In this paper we consider the problem of dynamic clustering, where clustermemberships may change over time and clusters may split and merge over time,thus creating new clusters and destroying existing ones. We propose a Bayesiannonparametric approach to dynamic clustering via mixture modeling. Our approachrelies on a novel time-dependent nonparametric prior defined by combining: i) acopula-based transformation of a Gaussian autoregressive process; ii) thestick-breaking construction of the Dirichlet process. Posterior inference isperformed through a particle Markov chain Monte Carlo algorithm which issimple, computationally efficient and scalable to massive datasets. Advantagesof the proposed approach include flexibility in applications, ease ofcomputations and interpretability. We present an application of our dynamicBayesian nonparametric mixture model to the study the temporal dynamics ofgender stereotypes in adjectives and occupations in the 20th and 21st centuriesin the United States. Moreover, to highlight the flexibility of our model wepresent additional applications to time-dependent data with covariates and withspatial structure."
Joint Clustering and Registration of Functional Data,"Yafeng Zhang, Donatello Telesca",2014/03/27,http://arxiv.org/abs/1403.7134v1,"Curve registration and clustering are fundamental tools in the analysis offunctional data. While several methods have been developed and explored foreither task individually, limited work has been done to infer functionalclusters and register curves simultaneously. We propose a hierarchical modelfor joint curve clustering and registration. Our proposal combines a Dirichletprocess mixture model for clustering of common shapes, with a reproducingkernel representation of phase variability for registration. We show howinference can be carried out applying standard posterior simulation algorithmsand compare our method to several alternatives in both engineered data and abenchmark analysis of the Berkeley growth data. We conclude our investigationwith an application to time course gene expression."
Heterogeneous Regression Models for Clusters of Spatial Dependent Data,"Zhihua Ma, Yishu Xue, Guanyu Hu",2019/07/04,http://arxiv.org/abs/1907.02212v4,"In economic development, there are often regions that share similar economiccharacteristics, and economic models on such regions tend to have similarcovariate effects. In this paper, we propose a Bayesian clustered regressionfor spatially dependent data in order to detect clusters in the covariateeffects. Our proposed method is based on the Dirichlet process which provides aprobabilistic framework for simultaneous inference of the number of clustersand the clustering configurations. The usage of our method is illustrated bothin simulation studies and an application to a housing cost dataset of Georgia."
